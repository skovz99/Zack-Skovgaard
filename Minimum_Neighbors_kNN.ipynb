{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsslsB8rm2ifWqC28LyT85",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skovz99/Zack-Skovgaard/blob/main/Minimum_Neighbors_kNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5WEKClngZH_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# training data\n",
        "data = [(13, 14, 1), (11, 8, 1), (4, 7, 0), (5, 8, 0), (10, 1, 1)]\n",
        "data_df = pd.DataFrame(data, columns=[\"X\", \"Y\", \"Classification\"])\n",
        "length = len(data_df)\n",
        "\n",
        "# testing data\n",
        "new_data = [(3, 4, 0), (11, 8, 1), (5, 17, 1), (15, 8, 1), (10, 11, 1)]\n",
        "new_data_df = pd.DataFrame(new_data, columns=[\"X\", \"Y\", \"Classification\"])\n",
        "\n",
        "# Return the classification values as a numpy array\n",
        "classification = data_df['Classification'].to_numpy()\n",
        "\n",
        "# zip the X and Y columns together\n",
        "zipped = [list(i) for i in zip(data_df['X'], data_df['Y'])]\n",
        "\n",
        "# find the nearest neighboring points to each of the X,Y coordinates in the data_df\n",
        "nbrs = NearestNeighbors(n_neighbors=length, algorithm='ball_tree').fit(zipped)\n",
        "distances, indices = nbrs.kneighbors(zipped)\n",
        "\n",
        "# Get the classification values of the nearest neighbors\n",
        "nearest_neighbors_classification = classification[indices]\n",
        "\n",
        "# Calculate the majority vote for each subset of neighbors\n",
        "majority_votes = []\n",
        "num_columns = nearest_neighbors_classification.shape[1]\n",
        "\n",
        "for x in range(1, num_columns + 1):\n",
        "    subset_neighbors = nearest_neighbors_classification[:, :x]\n",
        "    majority_vote = pd.DataFrame(subset_neighbors).mode(axis=1)[0]\n",
        "    majority_votes.append(majority_vote)\n",
        "\n",
        "# Concatenate the majority votes along the columns to create a new DataFrame\n",
        "majority_votes_df = pd.concat(majority_votes, axis=1)\n",
        "\n",
        "# Rename the columns in the majority_votes_df\n",
        "new_columns = [f'Majority Vote {x}' for x in range(num_columns)]\n",
        "majority_votes_df.columns = new_columns\n",
        "majority_votes_df = majority_votes_df.drop(['Majority Vote 0'], axis=1)\n",
        "\n",
        "minimum_nbrs = []\n",
        "# Iterate through the rows of the majority_votes_df\n",
        "for index, row in majority_votes_df.iterrows():\n",
        "    # Check if the majority vote row matches the correct classification\n",
        "    if (row[:-1] == data_df.at[index, 'Classification']).any():\n",
        "        # Get the index of the first correct classification\n",
        "        first_correct_idx = (row[:-1] == data_df.at[index, 'Classification']).idxmax()\n",
        "        # Get the minimum number of majority votes for this column\n",
        "        minimum_nbrs.append(int(first_correct_idx.split()[-1]))\n",
        "    else:\n",
        "        # If no correct classification found in this row, set it to -1\n",
        "        minimum_nbrs.append(-1)\n",
        "\n",
        "data_df['Minimum Neighbors'] = minimum_nbrs\n",
        "minimum_for_testing = data_df['Minimum Neighbors'].to_numpy()\n",
        "\n",
        "# Adding each pair from new_data_df to data_df as individual DataFrames\n",
        "resulting_dfs = []\n",
        "for idx, pair in enumerate(new_data):\n",
        "    new_df = pd.concat([data_df, pd.DataFrame([pair], columns=[\"X\", \"Y\", \"Classification\"])], ignore_index=True)\n",
        "    resulting_dfs.append(new_df)\n",
        "\n",
        "# determine the minimum nearest neighbors to assign to the testing data\n",
        "ultra = []\n",
        "for new_df in resulting_dfs:\n",
        "    zipped_testing = [list(i) for i in zip(new_df['X'], new_df['Y'])]  # Use the new DataFrame\n",
        "    nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(zipped_testing)  # Use zipped_testing\n",
        "    distances, indices = nbrs.kneighbors(zipped_testing)\n",
        "    ultra_df = pd.DataFrame(indices)\n",
        "    ultra.append(ultra_df)\n",
        "\n",
        "minimum_neighbors_test = []\n",
        "for ult in ultra:\n",
        "  ult['Minimum Neighbors'] = data_df['Minimum Neighbors']\n",
        "  finding = ult.iloc[-1, 1]\n",
        "  minimum_neighbors_test.append(ult['Minimum Neighbors'][finding])\n",
        "\n",
        "new_data_df['Min Neighbors'] = minimum_neighbors_test\n",
        "\n",
        "# Extract the features (X, Y) and labels (Class) from the training data\n",
        "X_train = data_df[['X', 'Y']]\n",
        "y_train = data_df['Classification']\n",
        "\n",
        "# Loop through each testing data point and determine the classification\n",
        "predictions = []\n",
        "for index, test_point in new_data_df.iterrows():\n",
        "  X_test = test_point[['X', 'Y']].values.reshape(1, -1)\n",
        "  k_neighbors = int(test_point['Min Neighbors'])\n",
        "  knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "  knn.fit(X_train, y_train)\n",
        "  predicted_class = knn.predict(X_test)[0]\n",
        "  predictions.append(predicted_class)\n",
        "\n",
        "new_data_df['Predictions'] = predictions\n",
        "\n",
        "# Comparison of Classification of the testing dataset to the predictions on the testing dataset\n",
        "new_data_df['Accuracy'] = np.where(new_data_df['Classification'] == new_data_df['Predictions'], 1, 0)\n",
        "new_data_df['True Positive Logic'] = np.where(new_data_df['Classification'] == 1, new_data_df['Predictions'], np.nan)\n",
        "True_P = np.nanmean(new_data_df['True Positive Logic']) * 100\n",
        "new_data_df['True Negative Logic'] = np.where(new_data_df['Classification'] == 0, new_data_df['Predictions'], np.nan)\n",
        "True_N = ((new_data_df['True Negative Logic'] == 0).sum() / (new_data_df['Classification'] == 0).sum()) * 100\n",
        "new_data_df['False Negative Logic'] = np.where((new_data_df['Classification'] == 1) & (new_data_df['Predictions'] == 0), 1, np.nan)\n",
        "False_N = ((new_data_df['False Negative Logic'] == 1).sum() / (new_data_df['Classification'] == 1).sum()) * 100\n",
        "new_data_df['False Positive Logic'] = np.where((new_data_df['Classification'] == 0) & (new_data_df['Predictions'] == 1), 1, np.nan)\n",
        "False_P = ((new_data_df['False Positive Logic'] == 1).sum() / (new_data_df['Classification'] == 0).sum()) * 100\n",
        "new_data_df"
      ]
    }
  ]
}